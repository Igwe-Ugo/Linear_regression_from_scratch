# ğŸ“˜ Linear Regression from Scratch in Python

This project is a **from-scratch implementation of Linear Regression** using only **NumPy**, without relying on high-level machine learning libraries such as Scikit-Learn or TensorFlow. It demonstrates both **single-variable** and **multiple-variable** regression, and compares results against Scikit-Learnâ€™s `LinearRegression` for validation.

---

## ğŸš€ Features

* Implemented **gradient descent** for parameter optimization.
* Supports:

  * **Single-feature regression** (e.g., `MedInc â†’ MedHouseVal`)
  * **Multiple-feature regression** (all 8 features of the California Housing dataset)
* Calculates evaluation metrics:

  * Mean Squared Error (MSE)
  * Root Mean Squared Error (RMSE)
  * Mean Absolute Error (MAE)
  * RÂ² Score
* Visualizations:

  * Regression line for single-feature case.
  * Predicted vs actual scatter plot for multiple features.
  * Cost function convergence plot.
* Validated against **Scikit-Learn** results.

---

## ğŸ“Š Results Summary

### âœ… Single Feature (Median Income â†’ Median House Value)

* **From Scratch:** RÂ² â‰ˆ 0.4589
* **Scikit-Learn:** RÂ² â‰ˆ 0.4589
* Parameters nearly identical (`w â‰ˆ 0.6904`, `b â‰ˆ -0.0007`)

### âœ… Multiple Features (All 8 Features â†’ Median House Value)

* **From Scratch:** RÂ² â‰ˆ 0.5775
* **Scikit-Learn:** RÂ² â‰ˆ 0.5758
* Both models produced almost identical error metrics.

ğŸ“Œ Takeaway: Gradient descent from scratch matches Scikit-Learnâ€™s Ordinary Least Squares implementation, and adding more features significantly improves model performance.

---

## ğŸ“‚ Project Structure

```
linear_regression_from_scratch/
â”‚â”€â”€ data/                  # Dataset (California Housing from sklearn.datasets)
â”‚â”€â”€ linear_regression_from_scratch.py   # Main implementation
â”‚â”€â”€ plots/                 # Visualizations (regression lines, cost curves, residuals)
â”‚â”€â”€ README.md              # Project documentation
```

---

## âš™ï¸ Installation & Usage

1. Clone this repository:

   ```bash
   git clone https://github.com/your-username/linear_regression_from_scratch.git
   cd linear_regression_from_scratch
   ```

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

   *(Required: `numpy`, `matplotlib`, `scikit-learn`)*

3. Run the script:

   ```bash
   python linear_regression_from_scratch.py
   ```

---

## ğŸ“ˆ Example Plots

### Single Feature Regression

Scatter plot with regression line (`MedInc â†’ MedHouseVal`).

### Multiple Feature Regression

Predicted vs actual scatter plot and cost curve showing gradient descent convergence.

---

## ğŸ”¬ Learning Outcomes

* Hands-on understanding of **gradient descent** for optimization.
* Difference between **iterative gradient descent** and **closed-form OLS solution**.
* Importance of using multiple features for better predictive performance.
* How to evaluate regression models beyond accuracy (MSE, RMSE, MAE, RÂ²).

---

## ğŸ“š References

* [Scikit-Learn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
* Andrew Ngâ€™s Machine Learning course
* California Housing Dataset (`sklearn.datasets.fetch_california_housing`)

---

## âœï¸ Author

Developed by **Igwe Ugochukwu Edwin (https://github.com/Igwe-Ugo)** â€” as part of my journey to deeply understand **Machine Learning fundamentals by building models from scratch**.

